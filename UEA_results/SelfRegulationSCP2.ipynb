{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b56d532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import ipynbname\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffe04505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# set the hypers for the model\n",
    "from argparse import Namespace\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "config = Namespace()\n",
    "\n",
    "config.batch_size = 2\n",
    "config.padding_idx = 99999\n",
    "config.defaut_max_size = 2024\n",
    "# config.defaut_max_size_hash = 500\n",
    "\n",
    "config.ts_max_length = None\n",
    "\n",
    "config.with_feature_padding = True\n",
    "config.with_feature_prompt = True \n",
    "\n",
    "config.ts_feature_size = None\n",
    "config.ts_max_idx = None\n",
    "\n",
    "config.hidden_dim = 7\n",
    "config.with_prompt = True \n",
    "config.TimeLangNet_embedding_dim = 7\n",
    "config.TimeLangNet_layers = 1\n",
    "config.TimeLangNet_heads  = 1\n",
    "config.TimeLangNet_d_k = 2\n",
    "config.TimeLangNet_d_v = 2\n",
    "config.num_class = None\n",
    "\n",
    "config.epoch = 30\n",
    "# config.lr = 5e-4\n",
    "config.lr = 0.001\n",
    "config.l2_weight = 0.01\n",
    "\n",
    "config.ALPHA = 0.4\n",
    "config.BETA = 0.6\n",
    "config.GAMMA = 1\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffabefe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ArticularyWordRecognition'], ['AtrialFibrillation'], ['BasicMotions'], ['Cricket'], ['DuckDuckGeese'], ['EigenWorms'], ['Epilepsy'], ['EthanolConcentration'], ['ERing'], ['FaceDetection'], ['FingerMovements'], ['HandMovementDirection'], ['Handwriting'], ['Heartbeat'], ['Libras'], ['LSST'], ['MotorImagery'], ['NATOPS'], ['PenDigits'], ['PEMS-SF'], ['PhonemeSpectra'], ['RacketSports'], ['SelfRegulationSCP1'], ['SelfRegulationSCP2'], ['StandWalkJump'], ['UWaveGestureLibrary'], ['InsectWingbeat']]\n",
      "====================================RUNNING=====================================\n",
      "-----------------------------['SelfRegulationSCP2']-----------------------------\n",
      "Loading data...............................................................Done.\n"
     ]
    }
   ],
   "source": [
    "path=\"Multivariate_ts/\" #datasets path \n",
    "flist = pd.read_csv(\"MSTC_Data.csv\", header=None)\n",
    "flist = flist.to_numpy().tolist()\n",
    "\n",
    "print(flist)\n",
    "\n",
    "def readucr(filename):\n",
    "    data= load_from_tsfile_to_dataframe(filename)\n",
    "    return data\n",
    "dataset_names = [['SelfRegulationSCP2']]\n",
    "\n",
    "def preprocess_data(x, y):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    x = x.to_numpy()\n",
    "    class_le = LabelEncoder()\n",
    "    y_encoded = class_le.fit_transform(y.copy())\n",
    "    channels = x.shape[1]\n",
    "    data_row = len(x[0][0])\n",
    "    x_processed = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_sample = np.concatenate(x[i], axis=0).reshape(channels, data_row, 1)\n",
    "        x_processed.append(x_sample)\n",
    "    \n",
    "    x_float = np.float32(np.array(x_processed)[:,:,:,0])\n",
    "    \n",
    "    return x_float, np.float32(y_encoded)\n",
    "\n",
    "results = pd.DataFrame(index = dataset_names,\n",
    "                       columns = [\"accuracy_mean\",\n",
    "                                  \"accuracy_standard_deviation\",\n",
    "                                  \"time_training_seconds\",\n",
    "                                  \"time_test_seconds\"],\n",
    "                       data = 0)\n",
    "results.index.name = \"dataset\"\n",
    "\n",
    "print(f\"RUNNING\".center(80, \"=\"))\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"{dataset_name}\".center(80, \"-\"))\n",
    "\n",
    "    # -- read data -------------------------------------------------------------\n",
    "\n",
    "    print(f\"Loading data\".ljust(80 - 5, \".\"), end = \"\", flush = True)\n",
    "    x_train, y_train = readucr(path + dataset_name[0] + '/' + dataset_name[0] + '_TRAIN.ts')\n",
    "    X_train, Y_train = preprocess_data(x_train, y_train)\n",
    "\n",
    "    x_test, y_test = readucr(path + dataset_name[0] + '/' + dataset_name[0] + '_TEST.ts')\n",
    "    X_test, Y_test = preprocess_data(x_test, y_test)\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df3251c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 7, 1152), (200,), (180, 7, 1152), (180,), 1.0, 1.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape, max(Y_train), max(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d633ad43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1152, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, config.ts_feature_size, config.ts_max_length = X_train.shape\n",
    "config.num_class = int(max(Y_train) + 1)\n",
    "config.ts_feature_size, config.ts_max_length, config.num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "697619f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TimeLangNet_Encoder:\n",
    "    def __init__(self, bins='auto'):\n",
    "        self.bins = bins\n",
    "        self.bin_edges_ = None\n",
    "        self.train_type = 1\n",
    "        \n",
    "    def fit(self, X, feature_names):\n",
    "        batch_size, feature_dim, feature_length = X.shape\n",
    "        self.bin_edges_ = []\n",
    "\n",
    "        for i in range(feature_dim):\n",
    "            feature_data = X[:, i, :].flatten()\n",
    "\n",
    "            if isinstance(self.bins, str) and self.bins == 'auto':\n",
    "                bins = np.histogram_bin_edges(feature_data, bins='auto')\n",
    "            elif isinstance(self.bins, int):\n",
    "                bins = np.linspace(feature_data.min(), feature_data.max(), self.bins+1)\n",
    "            elif isinstance(self.bins, (np.ndarray, list, tuple)):\n",
    "                bins = np.array(self.bins)\n",
    "            elif isinstance(self.bins, dict):\n",
    "                for feature in feature_names:\n",
    "                    if feature in self.bins:\n",
    "                        bins = self.bins[feature]\n",
    "                        if not isinstance(bins, np.ndarray):\n",
    "                            bins = np.array(bins)\n",
    "                        self.bin_edges_.append(bins)\n",
    "                    else:\n",
    "                        raise ValueError(\"Bin edges are not provided for feature '%s'.\" % feature)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid bin definition.\")\n",
    "                \n",
    "            self.bin_edges_.append(bins)\n",
    " \n",
    "            \n",
    "    def process_add_prompt(self, input_list, k, ts_max_idxs):\n",
    "        result = []\n",
    "        \n",
    "        for sub_lst, max_idx in zip(input_list, ts_max_idxs):\n",
    "            if len(sub_lst) < k:\n",
    "                sub_lst += [max_idx - 1] * (k - len(sub_lst))\n",
    "                \n",
    "                if config.with_feature_prompt:\n",
    "                    result.append([max_idx - 2] + sub_lst)\n",
    "                else:\n",
    "                    result.append(sub_lst)\n",
    "            else:\n",
    "                if config.with_feature_prompt:\n",
    "                    result.append([max_idx - 2] + sub_lst[-k:])\n",
    "                else:\n",
    "                    result.append(sub_lst[-k:])\n",
    "        return result\n",
    "\n",
    "    def transform(self, X, ts_max_idxs, max_length):\n",
    "        if self.bin_edges_ is None:\n",
    "            raise ValueError(\"The fit method should be called before transform.\")\n",
    "\n",
    "        batch_size, feature_dim, length = X.shape\n",
    "        full_binned_features = []\n",
    "\n",
    "        if ts_max_idxs is None:\n",
    "            ts_max_idxs = [len(bins) + 1 for bins in self.bin_edges_]\n",
    "            if config.with_feature_padding:\n",
    "                ts_max_idxs = [max_idx + 1 for max_idx in ts_max_idxs]\n",
    "            if config.with_feature_prompt:\n",
    "                ts_max_idxs = [max_idx + 1 for max_idx in ts_max_idxs]\n",
    "                \n",
    "            config.ts_max_idxs = ts_max_idxs        \n",
    "        \n",
    "        if self.train_type:\n",
    "            binned_features_by_bs = []\n",
    "\n",
    "            batch_real_lengths = []\n",
    "            for j in range(batch_size):\n",
    "                binned_features = []\n",
    "                real_length = length\n",
    "                for i in range(feature_dim):\n",
    "                    bins = self.bin_edges_[i]\n",
    "                    binned_feature_transformer = [np.digitize(x, bins, right=True).tolist() for x in X[j:j+1, i]]   \n",
    "                    \n",
    "                    real_length = max(real_length, len(binned_feature_transformer))\n",
    "                    \n",
    "                    binned_feature_with_prompt = self.process_add_prompt(binned_feature_transformer, max_length, ts_max_idxs)\n",
    "                    binned_features.append(binned_feature_with_prompt)\n",
    "                    \n",
    "                binned_features_by_bs.append(binned_features)\n",
    "                batch_real_lengths.append(real_length)\n",
    "                \n",
    "            binned_features_array = np.squeeze(np.array(binned_features_by_bs))\n",
    "            \n",
    "            if batch_size == 1:\n",
    "                binned_features_array = np.expand_dims(binned_features_array, axis=0)\n",
    "                \n",
    "            return binned_features_array, batch_real_lengths\n",
    "    \n",
    "\n",
    "    def fit_transform(self, X, feature_names=None, ts_max_idxs=None, max_length=None):\n",
    "        self.fit(X, feature_names)\n",
    "        return self.transform(X, ts_max_idxs, max_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b47a3ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 12, 12, 12, 12, 12]\n",
      "[12, 12, 12, 12, 12, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_auto = TimeLangNet_Encoder(bins=8)\n",
    "\n",
    "X_train, X_trian_length = encoder_auto.fit_transform(X_train, ts_max_idxs=config.ts_max_idx, max_length=config.ts_max_length)\n",
    "print(config.ts_max_idxs)\n",
    "X_test, X_test_length = encoder_auto.fit_transform(X_test, ts_max_idxs=config.ts_max_idx, max_length=config.ts_max_length)\n",
    "print(config.ts_max_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7556e6b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([2, 7, 1153])\n",
      "tensor([[[10.,  4.,  4.,  ...,  6.,  6.,  6.],\n",
      "         [10.,  5.,  5.,  ...,  4.,  4.,  5.],\n",
      "         [10.,  5.,  5.,  ...,  5.,  5.,  5.],\n",
      "         ...,\n",
      "         [10.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         [10.,  5.,  5.,  ...,  4.,  4.,  4.],\n",
      "         [10.,  5.,  5.,  ...,  4.,  4.,  4.]],\n",
      "\n",
      "        [[10.,  5.,  4.,  ...,  5.,  5.,  5.],\n",
      "         [10.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
      "         [10.,  5.,  5.,  ...,  5.,  5.,  5.],\n",
      "         ...,\n",
      "         [10.,  5.,  5.,  ...,  5.,  5.,  5.],\n",
      "         [10.,  4.,  3.,  ...,  5.,  5.,  5.],\n",
      "         [10.,  4.,  4.,  ...,  4.,  4.,  4.]]])\n",
      "tensor([1152, 1152])\n",
      "label: tensor([1, 1])\n",
      "\n",
      "\n",
      "1\n",
      "torch.Size([2, 7, 1153])\n",
      "tensor([[[10.,  5.,  5.,  ...,  4.,  4.,  4.],\n",
      "         [10.,  6.,  6.,  ...,  3.,  3.,  4.],\n",
      "         [10.,  6.,  6.,  ...,  4.,  4.,  4.],\n",
      "         ...,\n",
      "         [10.,  5.,  5.,  ...,  3.,  3.,  3.],\n",
      "         [10.,  5.,  5.,  ...,  3.,  3.,  3.],\n",
      "         [10.,  5.,  5.,  ...,  3.,  3.,  3.]],\n",
      "\n",
      "        [[10.,  4.,  4.,  ...,  3.,  3.,  3.],\n",
      "         [10.,  4.,  4.,  ...,  6.,  6.,  6.],\n",
      "         [10.,  4.,  4.,  ...,  6.,  5.,  5.],\n",
      "         ...,\n",
      "         [10.,  4.,  4.,  ...,  6.,  6.,  5.],\n",
      "         [10.,  4.,  4.,  ...,  5.,  5.,  5.],\n",
      "         [10.,  4.,  4.,  ...,  5.,  5.,  5.]]])\n",
      "tensor([1152, 1152])\n",
      "label: tensor([1, 1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_dataloader(X, Y, lengths, batch_size=16, shuffle=True):\n",
    "\n",
    "    tensor_x = torch.Tensor(X)  \n",
    "    tensor_y = torch.Tensor(Y).long()  \n",
    "    tensor_lengths = torch.Tensor(lengths).long()  \n",
    "    dataset = TensorDataset(tensor_x, tensor_y, tensor_lengths)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = create_dataloader(X_train, Y_train, X_trian_length, batch_size=config.batch_size)\n",
    "test_dataloader = create_dataloader(X_test, Y_test, X_test_length, batch_size=config.batch_size)\n",
    "\n",
    "    \n",
    "cnt = 0\n",
    "for step, data in enumerate(test_dataloader):\n",
    "    if step > 1: break \n",
    "    print(step)\n",
    "    features , label, length= data\n",
    "    print(features.shape)\n",
    "    print(features)\n",
    "    print(length)\n",
    "    print('label:',label) \n",
    "    print(\"\\n\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "830d827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import math\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from random import * \n",
    "from torch.autograd import Variable\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "################### Utils     #########################\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    \n",
    "#####################   Embedding layers ###########################\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, max_len, d_model, dropout = 0.05):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "  \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # print(self.pe[:, :x.size(1)].shape)\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],  requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "    \n",
    "class Fusion(nn.Module):\n",
    "    def __init__(self, input_size, out=1, dropout=0.2):\n",
    "        super(Fusion, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, input_size)\n",
    "        self.linear2 = nn.Linear(input_size, out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init.xavier_normal_(self.linear1.weight)\n",
    "        init.xavier_normal_(self.linear2.weight)\n",
    "\n",
    "    def forward(self, input_embeddings):\n",
    "        emb = torch.stack(input_embeddings)\n",
    "        emb_score = F.softmax(self.linear2(torch.tanh(self.linear1(emb))), dim=0)\n",
    "        emb_score = self.dropout(emb_score)\n",
    "        out = torch.sum(emb_score * emb, dim=0)\n",
    "        return out\n",
    "\n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, \n",
    "                 feature_size,\n",
    "                 feature_max_idxs,\n",
    "                 d_model,\n",
    "                 max_len=2024,\n",
    "                 with_pos = False,\n",
    "                 with_prompt = True):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        \n",
    "        self.feature_size = feature_size\n",
    "        self.feature_max_idxs = feature_max_idxs\n",
    "        self.d_model = d_model\n",
    "        self.with_pos = with_pos \n",
    "        self.with_prompt = with_prompt\n",
    "        \n",
    "        self.embedding_layers = nn.ModuleList([nn.Embedding(num_embeddings=self.feature_max_idxs[i], embedding_dim=self.d_model, padding_idx = self.feature_max_idxs[i] - 1) for i in range(feature_size)])\n",
    "        if self.with_pos:\n",
    "            self.pos_embedding = PositionalEncoding(max_len, d_model)  # position embedding\n",
    "        self.prompt_token_embedding = nn.Parameter(torch.zeros(1, 1, self.d_model))\n",
    "        self.feature_weight = nn.Parameter(torch.zeros(self.feature_size))\n",
    "        self.fusion_layer = Fusion(input_size = self.d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def get_feature_embeding_with_sum(self, x):\n",
    "        \n",
    "        features_embeddings = []\n",
    "        for i in range(self.feature_size):\n",
    "            embedded_feature = self.embedding_layers[i](x[:, i, :].long()) # [bsz, max_len] -> [bsz, max_len, hidden_dim]\n",
    "            features_embeddings.append(embedded_feature)\n",
    "        features_embeddings = torch.stack(features_embeddings)\n",
    "        features_embedding = torch.sum(features_embeddings, dim=0)  #len*emb_dim\n",
    "#         features_embedding = self.fusion_layer(features_embeddings)\n",
    "        \n",
    "        return features_embedding\n",
    "    \n",
    "    def get_feature_embedding_with_add(self, x):\n",
    "        bsz, fsz, seq_len = x.size()\n",
    "            \n",
    "        # feature embeddings\n",
    "        features_embedding = torch.zeros(bsz, seq_len, self.d_model).to(device)\n",
    "        \n",
    "        for i in range(self.feature_size):\n",
    "            \n",
    "            embedded_feature = self.embedding_layers[i](x[:, i, :].long()) # [bsz, max_len] -> [bsz, max_len, hidden_dim]\n",
    "            \n",
    "            features_embedding += self.feature_weight[i] * embedded_feature\n",
    "        \n",
    "        return features_embedding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x : [bsz, feature_size, max_len]\n",
    "\n",
    "        x_embedding = self.get_feature_embedding_with_add(x)\n",
    "        \n",
    "        if self.with_prompt:\n",
    "            prompt_token = self.prompt_token_embedding.expand(x.size(0), -1, -1)\n",
    "            x_embedding = torch.cat([prompt_token, x_embedding], dim=1) # [bsz, max_len, dim]\n",
    "        \n",
    "        if self.with_pos:\n",
    "            x_embedding = self.pos_embedding(x_embedding)\n",
    "\n",
    "        return self.norm(x_embedding)\n",
    "\n",
    "###################### main model #####################################\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "    \n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_heads=8,\n",
    "                 scale=None, \n",
    "                 attention_dropout=0.1, \n",
    "                 output_attention=False, \n",
    "                 future_mask_flag = False,\n",
    "                 ):\n",
    "        super(FullAttention, self).__init__()\n",
    "        \n",
    "        self.scale = scale\n",
    "        self.future_mask_flag = future_mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) / (sqrt(E) + 1e-6)\n",
    "\n",
    "        if self.future_mask_flag:\n",
    "            future_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "            batch_size, len_mask = future_mask.size()\n",
    "            future_mask = future_mask.view(batch_size, 1, len_mask, 1)\n",
    "            future_mask = future_mask.expand(-1, self.n_heads, -1, -1)\n",
    "            scores.masked_fill_(future_mask, -1e10)\n",
    "        if attn_mask != None:\n",
    "            #             attn_mask = attn_mask.unsqueeze(1).expand(-1, L, -1).bool()\n",
    "            #             attn_mask = attn_mask.unsqueeze(1).expand(-1, self.n_heads, -1, -1)\n",
    "            scores.masked_fill_(attn_mask, -1e10)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "\n",
    "class TimeLangNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feature_size,\n",
    "                 feature_max_idxs,\n",
    "                 num_class,\n",
    "                 max_len = 2024,\n",
    "                 n_layers = 6,  # number of Encoder of Encoder Layer\n",
    "                 n_heads = 12,  # number of heads in Multi-Head Attention\n",
    "                 d_model = 768, # Embedding Size\n",
    "                 d_ff = 3072,   # 4*d_model, FeedForward dimension\n",
    "                 d_k = 64,      # dimension of K(=Q), V\n",
    "                 d_v = 64,       # dimension of K(=Q), V\n",
    "                 output_dim = 256,\n",
    "                 with_prompt = True,\n",
    "                 future_mask_flag = False,\n",
    "                 ):\n",
    "        super(TimeLangNet, self).__init__()\n",
    "            \n",
    "        # hypers for the model\n",
    "        self.feature_size, = feature_size,\n",
    "        self.feature_max_idxs = feature_max_idxs\n",
    "        self.max_len = max_len\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = output_dim \n",
    "        self.num_classes = num_class \n",
    "        \n",
    "        # flags  \n",
    "        self.future_mask_flag = future_mask_flag\n",
    "        self.with_prompt = with_prompt\n",
    "                                             \n",
    "        # modules for the model\n",
    "        self.embedding = FeatureEmbedding(feature_size = feature_size, \n",
    "                                          feature_max_idxs = feature_max_idxs,  \n",
    "                                          d_model = d_model, \n",
    "                                          max_len = max_len, \n",
    "                                          with_prompt = with_prompt) \n",
    "\n",
    "        self.dropout =  nn.Dropout(0.1)\n",
    "#         self.encoder = Encoder(d_model= d_model, d_keys = d_k, d_values = d_v, n_heads=n_heads, n_layers = n_layers,d_ff=d_ff,)\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(n_heads = self.n_heads,\n",
    "                                      output_attention = True, \n",
    "                                      future_mask_flag = False, \n",
    "                                      ), \n",
    "                        d_model = self.d_model, \n",
    "                        n_heads = self.n_heads,\n",
    "                        d_keys = self.d_k,\n",
    "                        d_values = self.d_v,\n",
    "                    ),\n",
    "                    d_model = self.d_model,\n",
    "                    d_ff = self.d_ff\n",
    "                ) for l in range(self.n_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(self.d_model)\n",
    "        )\n",
    "        self.out_linear = nn.Linear(self.d_model, output_dim)\n",
    "        \n",
    "        self.act = F.gelu\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(output_dim, num_class)\n",
    "        \n",
    "    def forward(self, input_features, valid_len):\n",
    "        \n",
    "        # hypers \n",
    "        bsz, fsz, max_len = input_features.size()\n",
    "        padding_mask = self.get_padding_mask(input_features) # [bsz, max_len]\n",
    "        embedded_features = self.embedding(input_features)  \n",
    "        transformer_output, _ = self.encoder(embedded_features, attn_mask=padding_mask) # BS*length*hidden_dim\n",
    "        transformer_output = self.act(transformer_output)\n",
    "        transformer_output = self.dropout(transformer_output)\n",
    "        output_represenetations = self.out_linear(transformer_output.mean(1))\n",
    "        \n",
    "        output = self.fc(output_represenetations)\n",
    "        \n",
    "#         return nn.functional.softmax(output, dim=1)\n",
    "        return output\n",
    "                                             \n",
    "    \n",
    "    def get_padding_mask(self, input_features):\n",
    "            bsz, fsz, max_len = input_features.size()\n",
    "#             max_len = max_len + 1 if self.with_prompt else max_len\n",
    "            \n",
    "            padding_mask = (input_features.sum(1)) == (sum(self.feature_max_idxs) - fsz) # [bsz, max_len]\n",
    "            if self.with_prompt:\n",
    "                padding_mask = torch.cat([torch.zeros(bsz,1).cuda(), padding_mask], dim=1) # [bsz, max_len +1 ]\n",
    "                padding_mask = padding_mask.bool().unsqueeze(1).repeat(1, max_len + 1, 1)\n",
    "            else:\n",
    "                padding_mask = padding_mask.bool().unsqueeze(1).repeat(1, max_len, 1)\n",
    "            padding_mask = padding_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "\n",
    "            \n",
    "            return padding_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9fff4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, f1_score, precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.nn import Linear, ReLU, Sigmoid, Module, BCELoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau,CosineAnnealingLR,StepLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class MyModel_FinLangNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ts_feature_size,\n",
    "                 ts_max_idxs,\n",
    "                 num_class,\n",
    "                 d_model=64,\n",
    "                 n_layers=4,\n",
    "                 n_heads=8,\n",
    "                 d_ff=64*4,\n",
    "                 d_k=8,\n",
    "                 d_v=8,\n",
    "                 hidden_dim=64,\n",
    "                ):\n",
    "        super(MyModel_FinLangNet, self).__init__()\n",
    "        \n",
    "        # hypers \n",
    "        self.ts_len = ts_feature_size\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.embedding_dim = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.hidden_dim = 64\n",
    "        self.ts_max_idxs = ts_max_idxs\n",
    "        self.num_class = num_class\n",
    "        # hyper functions for the model\n",
    "        self.act = F.gelu\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "        # category_feature\n",
    "        # hyper parameters for the model        \n",
    "        self.TimeLangNet = TimeLangNet(self.ts_len,  \n",
    "                 feature_max_idxs = ts_max_idxs,\n",
    "                 num_class = self.num_class ,\n",
    "                 n_layers =  self.n_layers  ,  # number of Encoder of Encoder Layer\n",
    "                 n_heads  =  self.n_heads   ,  # number of heads in Multi-Head Attention\n",
    "                 d_model  =  self.d_model   , # Embedding Size\n",
    "                 d_ff     =  self.d_ff      ,   # 4*d_model, FeedForward dimension\n",
    "                 d_k      =  self.d_k       ,      # dimension of K(=Q), V\n",
    "                 d_v      =  self.d_v       ,      # dimension of K(=Q), V\n",
    "                 output_dim = 256, \n",
    "        )\n",
    "    \n",
    "    def forward(self, \n",
    "                ts_feature, \n",
    "                len_ts,\n",
    "                ):\n",
    "        \n",
    "\n",
    "        ts_feature_input =  ts_feature #BS*dim*length\n",
    "        ts_out = self.TimeLangNet(ts_feature_input, len_ts)\n",
    "        \n",
    "        return ts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1415ca6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel_FinLangNet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (TimeLangNet): TimeLangNet(\n",
      "    (embedding): FeatureEmbedding(\n",
      "      (embedding_layers): ModuleList(\n",
      "        (0-6): 7 x Embedding(12, 7, padding_idx=11)\n",
      "      )\n",
      "      (fusion_layer): Fusion(\n",
      "        (linear1): Linear(in_features=7, out_features=7, bias=True)\n",
      "        (linear2): Linear(in_features=7, out_features=1, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (norm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (encoder): Encoder(\n",
      "      (attn_layers): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): FullAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (query_projection): Linear(in_features=7, out_features=2, bias=True)\n",
      "            (key_projection): Linear(in_features=7, out_features=2, bias=True)\n",
      "            (value_projection): Linear(in_features=7, out_features=2, bias=True)\n",
      "            (out_projection): Linear(in_features=2, out_features=7, bias=True)\n",
      "          )\n",
      "          (conv1): Conv1d(7, 28, kernel_size=(1,), stride=(1,))\n",
      "          (conv2): Conv1d(28, 7, kernel_size=(1,), stride=(1,))\n",
      "          (norm1): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (out_linear): Linear(in_features=7, out_features=256, bias=True)\n",
      "    (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "{'Total': 3780, 'Trainable': 3780}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MyModel_FinLangNet(\n",
    "    ts_feature_size = config.ts_feature_size,\n",
    "    ts_max_idxs = config.ts_max_idxs,\n",
    "    num_class = config.num_class,\n",
    "    d_model = config.TimeLangNet_embedding_dim,\n",
    "    n_layers = config.TimeLangNet_layers,\n",
    "    n_heads = config.TimeLangNet_heads,\n",
    "    d_ff = config.TimeLangNet_embedding_dim * 4,\n",
    "    d_k = config.TimeLangNet_d_k,\n",
    "    d_v = config.TimeLangNet_d_v,\n",
    "    hidden_dim= 64, \n",
    ").to(device)\n",
    "\n",
    "#  --optimizer RAdam\n",
    "# optimizer =torch.optim.AdamW(model.parameters(), lr=0.001,)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=config.lr, \n",
    "                              betas=(0.9, 0.999),\n",
    "                              eps=1e-08, \n",
    "                              weight_decay=config.l2_weight)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# optimizer = torch.optim.RAdam(model.parameters(), lr=config.lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size = 3, gamma=0.2)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "def get_parameter_number(model):\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "print(get_parameter_number(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d273d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr : 0.001\n",
      "22:45:08 : Epoch: 1\n",
      "22:45:08 : Epoch [1/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6753 \n",
      "Accuracy: 0.5\n",
      "Precision: 0.25\n",
      "Recall: 0.5\n",
      "F1 Score: 0.3333333333333333\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        90\n",
      "           1       0.50      1.00      0.67        90\n",
      "\n",
      "    accuracy                           0.50       180\n",
      "   macro avg       0.25      0.50      0.33       180\n",
      "weighted avg       0.25      0.50      0.33       180\n",
      "\n",
      "save best model in epoch 0, best_accuracy is 0.5\n",
      "Current lr : 0.001\n",
      "22:45:09 : Epoch: 2\n",
      "22:45:09 : Epoch [2/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6994 \n",
      "Accuracy: 0.5\n",
      "Precision: 0.25\n",
      "Recall: 0.5\n",
      "F1 Score: 0.3333333333333333\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        90\n",
      "           1       0.50      1.00      0.67        90\n",
      "\n",
      "    accuracy                           0.50       180\n",
      "   macro avg       0.25      0.50      0.33       180\n",
      "weighted avg       0.25      0.50      0.33       180\n",
      "\n",
      "Current lr : 0.001\n",
      "22:45:10 : Epoch: 3\n",
      "22:45:10 : Epoch [3/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6630 \n",
      "Accuracy: 0.6\n",
      "Precision: 0.6076555023923444\n",
      "Recall: 0.6\n",
      "F1 Score: 0.5927601809954751\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54        90\n",
      "           1       0.58      0.73      0.65        90\n",
      "\n",
      "    accuracy                           0.60       180\n",
      "   macro avg       0.61      0.60      0.59       180\n",
      "weighted avg       0.61      0.60      0.59       180\n",
      "\n",
      "save best model in epoch 2, best_accuracy is 0.6\n",
      "Current lr : 0.0002\n",
      "22:45:11 : Epoch: 4\n",
      "22:45:11 : Epoch [4/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6879 \n",
      "Accuracy: 0.5\n",
      "Precision: 0.25\n",
      "Recall: 0.5\n",
      "F1 Score: 0.3333333333333333\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        90\n",
      "           1       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.50       180\n",
      "   macro avg       0.25      0.50      0.33       180\n",
      "weighted avg       0.25      0.50      0.33       180\n",
      "\n",
      "Current lr : 0.0002\n",
      "22:45:13 : Epoch: 5\n",
      "22:45:13 : Epoch [5/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6602 \n",
      "Accuracy: 0.5277777777777778\n",
      "Precision: 0.57355344883949\n",
      "Recall: 0.5277777777777778\n",
      "F1 Score: 0.44076903395591943\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.66        90\n",
      "           1       0.63      0.13      0.22        90\n",
      "\n",
      "    accuracy                           0.53       180\n",
      "   macro avg       0.57      0.53      0.44       180\n",
      "weighted avg       0.57      0.53      0.44       180\n",
      "\n",
      "Current lr : 0.0002\n",
      "22:45:14 : Epoch: 6\n",
      "22:45:14 : Epoch [6/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6629 \n",
      "Accuracy: 0.5666666666666667\n",
      "Precision: 0.5777649769585254\n",
      "Recall: 0.5666666666666667\n",
      "F1 Score: 0.5506337216745615\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.76      0.64        90\n",
      "           1       0.61      0.38      0.47        90\n",
      "\n",
      "    accuracy                           0.57       180\n",
      "   macro avg       0.58      0.57      0.55       180\n",
      "weighted avg       0.58      0.57      0.55       180\n",
      "\n",
      "Current lr : 4e-05\n",
      "22:45:15 : Epoch: 7\n",
      "22:45:15 : Epoch [7/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6521 \n",
      "Accuracy: 0.5444444444444444\n",
      "Precision: 0.5472689075630253\n",
      "Recall: 0.5444444444444444\n",
      "F1 Score: 0.5375360320842211\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59        90\n",
      "           1       0.56      0.42      0.48        90\n",
      "\n",
      "    accuracy                           0.54       180\n",
      "   macro avg       0.55      0.54      0.54       180\n",
      "weighted avg       0.55      0.54      0.54       180\n",
      "\n",
      "Current lr : 4e-05\n",
      "22:45:16 : Epoch: 8\n",
      "22:45:16 : Epoch [8/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6653 \n",
      "Accuracy: 0.5555555555555556\n",
      "Precision: 0.566137566137566\n",
      "Recall: 0.5555555555555556\n",
      "F1 Score: 0.537037037037037\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63        90\n",
      "           1       0.59      0.36      0.44        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.57      0.56      0.54       180\n",
      "weighted avg       0.57      0.56      0.54       180\n",
      "\n",
      "Current lr : 4e-05\n",
      "22:45:17 : Epoch: 9\n",
      "22:45:17 : Epoch [9/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7106 \n",
      "Accuracy: 0.5555555555555556\n",
      "Precision: 0.5578703703703703\n",
      "Recall: 0.5555555555555556\n",
      "F1 Score: 0.5510662177328844\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60        90\n",
      "           1       0.57      0.46      0.51        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.55       180\n",
      "weighted avg       0.56      0.56      0.55       180\n",
      "\n",
      "Current lr : 8.000000000000001e-06\n",
      "22:45:18 : Epoch: 10\n",
      "22:45:18 : Epoch [10/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6988 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5639617521643623\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5561659227816098\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60        90\n",
      "           1       0.58      0.46      0.51        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 8.000000000000001e-06\n",
      "22:45:20 : Epoch: 11\n",
      "22:45:20 : Epoch [11/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7060 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 8.000000000000001e-06\n",
      "22:45:21 : Epoch: 12\n",
      "22:45:21 : Epoch [12/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7310 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 1.6000000000000004e-06\n",
      "22:45:22 : Epoch: 13\n",
      "22:45:22 : Epoch [13/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6840 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 1.6000000000000004e-06\n",
      "22:45:23 : Epoch: 14\n",
      "22:45:23 : Epoch [14/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6959 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 1.6000000000000004e-06\n",
      "22:45:24 : Epoch: 15\n",
      "22:45:24 : Epoch [15/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7489 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 3.200000000000001e-07\n",
      "22:45:25 : Epoch: 16\n",
      "22:45:25 : Epoch [16/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7178 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 3.200000000000001e-07\n",
      "22:45:26 : Epoch: 17\n",
      "22:45:26 : Epoch [17/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6887 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 3.200000000000001e-07\n",
      "22:45:28 : Epoch: 18\n",
      "22:45:28 : Epoch [18/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6925 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 6.400000000000003e-08\n",
      "22:45:29 : Epoch: 19\n",
      "22:45:29 : Epoch [19/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6864 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 6.400000000000003e-08\n",
      "22:45:30 : Epoch: 20\n",
      "22:45:30 : Epoch [20/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7142 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 6.400000000000003e-08\n",
      "22:45:31 : Epoch: 21\n",
      "22:45:31 : Epoch [21/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6782 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 1.2800000000000007e-08\n",
      "22:45:32 : Epoch: 22\n",
      "22:45:32 : Epoch [22/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6738 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 1.2800000000000007e-08\n",
      "22:45:33 : Epoch: 23\n",
      "22:45:33 : Epoch [23/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7112 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 1.2800000000000007e-08\n",
      "22:45:34 : Epoch: 24\n",
      "22:45:34 : Epoch [24/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6818 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 2.5600000000000015e-09\n",
      "22:45:36 : Epoch: 25\n",
      "22:45:36 : Epoch [25/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7245 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 2.5600000000000015e-09\n",
      "22:45:37 : Epoch: 26\n",
      "22:45:37 : Epoch [26/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6735 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 2.5600000000000015e-09\n",
      "22:45:38 : Epoch: 27\n",
      "22:45:38 : Epoch [27/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6865 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 5.120000000000003e-10\n",
      "22:45:39 : Epoch: 28\n",
      "22:45:39 : Epoch [28/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6832 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 5.120000000000003e-10\n",
      "22:45:40 : Epoch: 29\n",
      "22:45:40 : Epoch [29/30],\n",
      "            Step [0],\n",
      "            Loss: 0.6860 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n",
      "Current lr : 5.120000000000003e-10\n",
      "22:45:41 : Epoch: 30\n",
      "22:45:41 : Epoch [30/30],\n",
      "            Step [0],\n",
      "            Loss: 0.7000 \n",
      "Accuracy: 0.5611111111111111\n",
      "Precision: 0.5646298472385429\n",
      "Recall: 0.5611111111111111\n",
      "F1 Score: 0.5550549141087018\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        90\n",
      "           1       0.58      0.44      0.50        90\n",
      "\n",
      "    accuracy                           0.56       180\n",
      "   macro avg       0.56      0.56      0.56       180\n",
      "weighted avg       0.56      0.56      0.56       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop_patience = 10 \n",
    "best_val_loss = float('inf')\n",
    "best_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import time, json, datetime \n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, f1_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "regression_criterion = torch.nn.MSELoss()\n",
    "\n",
    "def write_log(w):\n",
    "    t0 = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    info = \"{} : {}\".format(t0, w)\n",
    "    print(info)\n",
    "\n",
    "num_epochs = config.epoch\n",
    "\n",
    "def cal_accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_tmp = model.train()\n",
    "    train_loss = 0.0\n",
    "    train_cnt = 0\n",
    "    print(\"Current lr : {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    write_log('Epoch: {}'.format(epoch + 1))\n",
    "        \n",
    "    for step, (features, labels, lengths) in enumerate(train_dataloader):\n",
    "        ts_feature = features.to(device)\n",
    "        label = labels.long().to(device)\n",
    "        len_ts = lengths\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ts_feature, len_ts)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            msg = f\"\"\"Epoch [{epoch+1}/{num_epochs}],\n",
    "            Step [{step}],\n",
    "            Loss: {loss.item():.4f} \"\"\"\n",
    "            write_log(msg)\n",
    "        train_cnt += 1\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    val_tmp = model.eval()\n",
    "    val_loss = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_step, (features, labels, lengths) in enumerate(val_dataloader):\n",
    "            ts_feature = features.to(device)\n",
    "            label = labels.long().to(device)\n",
    "            len_ts = lengths\n",
    "            \n",
    "            outputs = model(ts_feature, len_ts)\n",
    "            loss = criterion(outputs, label)\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            all_preds.append(outputs.detach())\n",
    "            all_labels.append(label)\n",
    "                \n",
    "            if val_step % 100 == 0:\n",
    "                msg = f'Valid runing,Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}'\n",
    "                write_log(msg)\n",
    "\n",
    "    # Calculate metrics\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    probs = torch.nn.functional.softmax(all_preds, dim=1)\n",
    "    all_preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "    all_labels = all_labels.cpu().numpy()\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    class_report = classification_report(all_labels, all_preds)\n",
    "    \n",
    "    # Check if early stopping condition is met\n",
    "    current_val_loss = np.mean(val_loss)\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_accuracy = accuracy  \n",
    "        best_val_loss = current_val_loss\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0  # Reset counter if there is an improvement\n",
    "        write_log(f'Saved best model at epoch {epoch+1}, with validation loss {best_val_loss:.4f} and accuracy {best_accuracy:.4f}')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        write_log(f'No improvement in validation loss for {patience_counter} epochs')\n",
    "        \n",
    "    if patience_counter >= early_stop_patience:\n",
    "        write_log(f'Early stopping at epoch {epoch+1} ')\n",
    "        break\n",
    "\n",
    "write_log(f'Best validation loss: {best_val_loss:.4f}best validation accuracy is {best_accuracy:.4f}best model in epoch {best_epoch+1}')\n",
    "torch.save(model.state_dict(), f\"{dataset_names[0][0]}_model.pth\")\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{dataset_names[0][0]}_model.pth\"))\n",
    "model.to(device)\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on the test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, (features, labels, lengths) in enumerate(test_dataloader):\n",
    "        ts_feature = features.to(device)\n",
    "        label = labels.long().to(device)\n",
    "        len_ts = lengths\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(ts_feature, len_ts)\n",
    "        \n",
    "        # Get predictions\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "class_report = classification_report(all_labels, all_preds)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Classification Report\\n', class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c7fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
